# weather_project
En este proyecto de ETL (Extracci贸n, Transformaci贸n y Carga) de datos meteorol贸gicos, utilizaremos una arquitectura moderna y gratuita con herramientas de alta productividad.


La API p煤blica de
OpenWeatherMap para obtener datos clim谩ticos, Microsoft SQL
Server como base de datos relacional, y Python con sus potentes
bibliotecas para procesar y transformar informaci贸n. El objetivo
principal es crear un flujo de trabajo eficiente que nos permita
extraer datos meteorol贸gicos en tiempo real, almacenarlos de
manera estructurada y prepararnos para an谩lisis posteriores, todo
utilizando 煤nicamente recursos accesibles y sin costo adicional.
Paso a paso para desarrollar el proyecto:

Paso 1: Registro en la API de OpenWeatherMap

1. Ve al sitio web de [OpenWeatherMap](https://openweathermap.org/api) y
reg铆strate para obtener una clave de API (API key).
2. Guarda la clave de API, ya que la utilizaremos para hacer consultas a la API.


Paso 2: Instala SQLServer Microsoft:
(si ya esta instalado)
1. Crea una base de datos que llamaremos `weather_db` para almacenar la
informaci贸n extra铆da.



Paso 3: Python:
Installation 
Clone this repository:

git clone https://github.com/your-username/Weather-ETL.git
cd Weather-ETL
Instala los paquetes de Python requeridos:

pip install -r requirements.txt



Paso 4: Escribir el script de extracci贸n y carga en la
base de datos:
1. Crea un script en Python llamado `extract_transform_load.py` que har谩
la extracci贸n de datos desde la API de OpenWeatherMap y los almacenar谩
en la base de datos PostgreSQL.
2. Funci贸n para extraer datos de la API.
3. Funci贸n para transformar los datos.
4. Funci贸n para cargar los datos a SQLServer.
5. Proceso ETL.


Paso 5: Verificar los datos en SQLServer:
a. Despu茅s de correr el script de Python, puedes verificar que los datos se
hayan cargado correctamente en tu base de datos PostgreSQL ejecutando
una consulta en SQLServer.
b. Instala la biblioteca de Google BigQuery en tu entorno virtual.
c. Crea un script Python para cargar datos desde SQLserver a BigQuery.
d. Funci贸n para extraer los datos de PostgreSQL.
e. Funci贸n para cargar los datos a BigQuery.
f. Proceso ETL a BigQuery.
g. Configura las credenciales para acceder a Google Cloud siguiendo [esta
gu铆a](https://cloud.google.com/docs/authentication/getting-started).

Paso a paso para desarrollar el proyecto:
Opcional: Automatizaci贸n y Monitoreo
Si deseas automatizar este proceso, podr铆as usar un cron job en Linux
o el Programador de Tareas en Windows para ejecutar el script en
intervalos regulares.
